import { NextRequest, NextResponse } from 'next/server'

export async function POST(request: NextRequest) {
  try {
    console.log('ğŸš€ Chat API called')

    // API key ã®ãƒã‚§ãƒƒã‚¯
    if (!process.env.OPENAI_API_KEY) {
      console.error('âŒ OPENAI_API_KEY not found')
      return NextResponse.json(
        { error: 'OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“' },
        { status: 500 }
      )
    }

    console.log('âœ… OpenAI API KEY found:', process.env.OPENAI_API_KEY.substring(0, 20) + '...')

    const { message, conversationHistory = [], imageBase64, imageMimeType } = await request.json()

    console.log('ğŸ“¨ Received message:', {
      messageLength: message?.length,
      historyLength: conversationHistory?.length,
      hasImage: !!imageBase64
    })

    if (!message) {
      return NextResponse.json(
        { error: 'ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™' },
        { status: 400 }
      )
    }

    // ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰
    const messages = [
      {
        role: 'system',
        content: 'ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ä¸å¯§ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚'
      },
      ...conversationHistory,
      {
        role: 'user',
        content: imageBase64 ? [
          { type: 'text', text: message },
          {
            type: 'image_url',
            image_url: {
              url: `data:${imageMimeType || 'image/jpeg'};base64,${imageBase64}`
            }
          }
        ] : message
      }
    ]

    console.log('ğŸ”„ Calling OpenAI API...')

    // OpenAI APIå‘¼ã³å‡ºã— (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’è¿½åŠ )
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 30000) // 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: messages,
          max_tokens: 1000,
          temperature: 0.7,
          stream: false,
        }),
        signal: controller.signal
      })

      clearTimeout(timeoutId)

      console.log('âœ… OpenAI API response received, status:', response.status)

      if (!response.ok) {
        const errorData = await response.text()
        console.error('âŒ OpenAI API error:', errorData)

        // API ã‚¨ãƒ©ãƒ¼ã§ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’è¿”ã™
        return NextResponse.json({
          message: 'ã™ã¿ã¾ã›ã‚“ã€ç¾åœ¨AIã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }

      const completion = await response.json()
      const assistantMessage = completion.choices[0]?.message?.content

      if (!assistantMessage) {
        console.error('âŒ No assistant message in response')
        return NextResponse.json({
          message: 'ã™ã¿ã¾ã›ã‚“ã€å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }

      console.log('âœ… Successfully generated response')

      return NextResponse.json({
        message: assistantMessage,
        success: true
      })

    } catch (fetchError) {
      clearTimeout(timeoutId)
      throw fetchError
    }

  } catch (error) {
    console.error('âŒ Chat API error:', error)

    if (error instanceof Error) {
      console.error('Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack?.substring(0, 200)
      })

      // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
      if (error.name === 'AbortError') {
        return NextResponse.json({
          message: 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }

      // API ã‚¨ãƒ©ãƒ¼ã®è©³ç´°è¡¨ç¤º
      if (error.message.includes('insufficient_quota')) {
        return NextResponse.json({
          message: 'APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }

      if (error.message.includes('invalid_api_key')) {
        return NextResponse.json({
          message: 'APIã‚­ãƒ¼ã®è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }

      if (error.message.includes('rate_limit')) {
        return NextResponse.json({
          message: 'ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }

      // ä¸€èˆ¬çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
      if (error.message.includes('timeout') || error.message.includes('network') || error.message.includes('fetch')) {
        return NextResponse.json({
          message: 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚',
          success: true,
          fallback: true
        })
      }
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã§ç¢ºå®Ÿã«HTTP 200ã‚’è¿”ã™
    return NextResponse.json({
      message: 'ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ã¯ç¾åœ¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã§ã™ã€‚ã”ä¸ä¾¿ã‚’ãŠã‹ã‘ã—ã¦ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚',
      success: true,
      fallback: true
    })
  }
}